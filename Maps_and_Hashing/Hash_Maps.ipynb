{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## introdution to Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'o': 1, 'm': 2, 'a': 3, 'r': 4}\n"
     ]
    }
   ],
   "source": [
    "name = {}\n",
    "name['o'] = 1\n",
    "name['m'] = 2\n",
    "name['a'] = 3\n",
    "name['r'] = 4\n",
    "\n",
    "print(name)\n",
    "# {'o': 1, 'm': 2, 'a': 3, 'r': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(name['o'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d': [1], 'i': [2, 5], 'c': [3], 't': [4], 'o': [6], 'n': [7], 'a': [8], 'r': [9], 'y': [10]}\n"
     ]
    }
   ],
   "source": [
    "dictionary = {}\n",
    "dictionary['d'] = [1]\n",
    "dictionary['i'] = [2]\n",
    "dictionary['c'] = [3]\n",
    "dictionary['t'] = [4]\n",
    "dictionary['i'].append(5)\n",
    "dictionary['o'] = [6]\n",
    "dictionary['n'] = [7]\n",
    "dictionary['a'] = [8]\n",
    "dictionary['r'] = [9]\n",
    "dictionary['y'] = [10]\n",
    "print(dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: China - cities: ['Shanghai', 'q', 'z']\n",
      "country: India - cities: ['Bangalore', 'x', 'y']\n"
     ]
    }
   ],
   "source": [
    "locations = {'North America': {'USA': ['Mounatin View']}}\n",
    "locations['North America']['USA'].append('Atlanta')\n",
    "locations['Asia'] = {'India': ['Bangalore', 'x','y'], 'China':['Shanghai', 'z', 'q']}\n",
    "locations['Africa'] = {'Egypt': ['Cairo']}\n",
    "\n",
    "# print(locations['North America'])\n",
    "# TODO: print a list of all cities in usa in alphabetical order\n",
    "usa_loc = locations['North America']['USA']\n",
    "usa_loc.sort()\n",
    "for city in usa_loc:\n",
    "    print(city)\n",
    "\n",
    "# TODO: Print all cities in Asia, in alphabetic order, next to the name of the country\n",
    "asia_loc = locations['Asia']\n",
    "\n",
    "asia_loc_list = [element for element in asia_loc]\n",
    "# print(asia_loc_list)\n",
    "asia_loc_list.sort()\n",
    "for country in asia_loc_list:\n",
    "    locations['Asia'][country].sort()\n",
    "    print(f\"country: {country} - cities: {locations['Asia'][country]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Problem Statement <br>\n",
    "In a class of students, store heights for each student.<br>\n",
    "The problem in itself is very simple. We have the data of heights of each student. We want to store it so that next time someone asks for height of a student, we can easily return the value. But how can we store these heights?\n",
    "Obviously we can use a database and store these values. But, let's say we don't want to do that for now. We want to use a data structure to store these values as part of our program. For the sake of simplicity, our problem is limited to storing heights of students. But you can certainly imagine scenarios where you have to store such `key-value` pairs and later on when someone gives you a `key`, you can efficiently return the corrresponding `value`.\n",
    "\n",
    "The class diagram for HashMaps would look something like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n",
      "{-7327131530017758638: 160, -7338045405639255669: 180, 1013712772062587743: 110, -5369402461981849357: 200, -2135810465854363165: 210, -366575816089929790: 190}\n",
      "Time 0.0010018348693847656\n"
     ]
    }
   ],
   "source": [
    "class HashMap:\n",
    "    def __init__(self):\n",
    "        self.num = 0\n",
    "        self.size_map = 0\n",
    "\n",
    "    def hash(self, key):\n",
    "        n_hash = 0\n",
    "        for char in key:\n",
    "            n_hash += ord(char)\n",
    "        return n_hash % self.num+1\n",
    "\n",
    "    def put(self, key, value):\n",
    "        key = hash(key)\n",
    "        if self.size_map == 0:\n",
    "            self.map = {key: value}\n",
    "            self.size_map += 1\n",
    "        else:\n",
    "            self.map[key] = value\n",
    "            self.size_map += 1\n",
    "\n",
    "    def get(self, key):\n",
    "        key = hash(key)\n",
    "        return self.map[key]\n",
    "\n",
    "    def size(self):\n",
    "        return self.size_map\n",
    "\n",
    "    def print(self):\n",
    "        print(self.map)\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "start =time.time()\n",
    "\n",
    "s_class = HashMap()\n",
    "s_class.put('mohamed', 160)\n",
    "s_class.put('ahmed', 180)\n",
    "s_class.put('kh', 110)\n",
    "s_class.put('omar', 200)\n",
    "s_class.put('zizo', 210)\n",
    "s_class.put('mt', 190)\n",
    "\n",
    "\n",
    "print(s_class.get('mt'))\n",
    "s_class.print()\n",
    "s_class.size()\n",
    "end =time.time()\n",
    "\n",
    "print('Time', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Time 0.0\n"
     ]
    }
   ],
   "source": [
    "## creat hash map with list\n",
    "\n",
    "class HashMap:\n",
    "    def __init__(self, size):\n",
    "        self.num_entries = 0\n",
    "        self.size = size\n",
    "        self.map = [None] * self.size\n",
    "\n",
    "    def _get_hash(self, key):\n",
    "        hash = 0\n",
    "        for char in str(key):\n",
    "            hash += ord(char)\n",
    "        return hash % self.size\n",
    "    \n",
    "    def add(self, key, value):\n",
    "        key_hash = self._get_hash(key)\n",
    "        key_value = [key, value]\n",
    "        if self.map[key_hash] is None:\n",
    "            self.map[key_hash] = list([key_value])\n",
    "            self.num_entries += 1\n",
    "        else:\n",
    "            for pair in self.map[key_hash]:\n",
    "                if pair[0] == key:\n",
    "                    pair[1] = value\n",
    "                    return True\n",
    "            self.map[key_hash].append(key_value)\n",
    "            self.num_entries += 1\n",
    "        return True \n",
    "\n",
    "    def get(self, key):\n",
    "        key_hash = self._get_hash(key)\n",
    "        if self.map[key_hash] is not None:\n",
    "            for pair in self.map[key_hash]:\n",
    "                if pair[0] == key:\n",
    "                    return pair[1]\n",
    "        return None\n",
    "\n",
    "    def delete(self, key):\n",
    "        key_hash = self._get_hash(key)\n",
    "        if self.map[key_hash] is None:\n",
    "            return False\n",
    "        for i in range(0, len(self.map[key_hash])):\n",
    "            if self.map[key_hash][i][0] == key:\n",
    "                self.map[key_hash].pop(i)\n",
    "                self.num_entries -= 1\n",
    "        return True\n",
    "\n",
    "    def print(self):\n",
    "        print(\"{} hash buckets\".format(self.size))\n",
    "        for bucket in self.map:\n",
    "            if bucket is not None:\n",
    "                print(\"---\")\n",
    "                for pair in bucket:\n",
    "                    print(\"{}: {}\".format(pair[0], pair[1]))\n",
    "        print(\"\")\n",
    "\n",
    "start= time.time()\n",
    "hash_map = HashMap(6)\n",
    "hash_map.add(\"two\", 2)\n",
    "hash_map.add(\"three\", 3)\n",
    "hash_map.add(\"four\", 4)\n",
    "hash_map.add(\"five\", 5)\n",
    "hash_map.add(\"six\", 6)\n",
    "hash_map.add(\"seven\", 7)\n",
    "print(hash_map.get('two'))\n",
    "# hash_map.print()\n",
    "end =time.time()\n",
    "\n",
    "print('Time', end-start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrays\n",
    "\n",
    "Can we use arrays to store `key-value` pairs?\n",
    "\n",
    "We can certainly use one array to store the names of the students and use another array to store their corresponding heights at the corresponding indices.\n",
    "\n",
    "What will be the time complexity in this scenario?\n",
    "\n",
    "To obtain height of a student, say `Potter, Harry`, we will have to traverse the entire array and check if the value at a particular index matches `Potter, Harry`. Once we find the index in which this value is stored, we can use this index to obtain the height from the second array. \n",
    "\n",
    "Thus, because of this traveral, complexity for `get()` operation becomes $O(n)$. Even if we maintain a sorted array, the operation will not take less than $O(log(n))$ complexity.\n",
    "\n",
    "What happens if a student leaves a class? We will have to delete the entry corresponding to the student from both the arrays. \n",
    "\n",
    "This would require another traversal to find the index. And then we will have to shift our entire array to fill this gap. Again, the time complexity of operation becomes $O(n)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linked List\n",
    "\n",
    "Is it possible to use linked lists for this problem?\n",
    "\n",
    "We can certainly modify our `LinkedListNode` to have two different value attributes - one for name of the student and the other for height. \n",
    "\n",
    "But we again face the same problem. In the worst case, we will have to traverse the entire linked list to find the height of a particular student. Once again, the cost of operation becomes $O(n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacks and Queues\n",
    "\n",
    "Stacks and Queues are LIFO and FIFO data structures respectively. Can you think why they too do not make a good choice for storing `key-value` pairs?<br>\n",
    "Can we do better? Can you think of any data structure that allows for fast `get()` operation?<br>\n",
    "\n",
    "Let us circle back to arrays. \n",
    "\n",
    "When we obtain the element present at a particular index using something like `arr[3]`, the operation takes constant i.e. `O(1)` time. \n",
    "\n",
    "*For review - Does this constant time operation require further explanation?*\n",
    "\n",
    "\n",
    "\n",
    "If we think about `array indices as keys` and the `element present at those indices as values`, we can fairly conclude that at least for non-zero integer `keys`, we can use arrays.  \n",
    "\n",
    "However, like our current problem statement, we may not always have integer keys.\n",
    "\n",
    "`If only we had a function that could give us arrays indices for any key value that we gave it!`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "def hash_function(string):\n",
    "    hash_code = 0 \n",
    "    for character in string :\n",
    "        hash_code += ord(character)\n",
    "        return hash_code\n",
    "\n",
    "hash_code_1 = hash_function(\"abcd\")\n",
    "print(hash_code_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our hash function is working fine. But is this really a good hash function?\n",
    "\n",
    "For starters, it will return the same value for `abcd` and `bcda`. Do we want that? We can create 24 different permutations for the string `abcd` and each will have the same value. We cannot put 24 values to one index. \n",
    "\n",
    "Obviously, this makes it clear that our hash function must return unique values for unique objects. \n",
    "\n",
    "When two different inputs produce the same output, then we have something called a `collision`. An ideal hash function must be immune from producing collisions.  \n",
    "\n",
    "Let's think something else.\n",
    "\n",
    "Can product help? We will again run in the same problem. \n",
    "\n",
    "The honest answer is that we have differernt hash functions for different types of keys. The hash function for integers will be different from the hash function for strings, which again, will be different for some object of a class that you created. \n",
    "\n",
    "However, let's try to continue with our problem and try to come up with a hash function for strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hash Function for Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_array = [None for _ in range(10)]\n",
    "bucket_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5204554\n",
      "5054002\n"
     ]
    }
   ],
   "source": [
    "class HashMap:\n",
    "    \n",
    "    def __init__(self, initial_size=10):\n",
    "        self.bucket_array = [None for _ in range(initial_size)]\n",
    "        self.p = 37\n",
    "        self.num_entries = 0\n",
    "        \n",
    "    def put(self, key, value):\n",
    "        pass\n",
    "    \n",
    "    def get(self, key):\n",
    "        pass\n",
    "    \n",
    "    def get_bucket_index(self, key):\n",
    "        return self.get_hash_code(key)\n",
    "    \n",
    "    def get_hash_code(self, key):\n",
    "        key = str(key)\n",
    "        num_buckets = len(self.bucket_array)\n",
    "        current_coefficient = 1\n",
    "        hash_code = 0\n",
    "        for character in key:\n",
    "            hash_code += ord(character) * current_coefficient\n",
    "            current_coefficient *= self.p\n",
    "            current_coefficient = current_coefficient\n",
    "\n",
    "        return hash_code\n",
    "\n",
    "hash_map = HashMap()\n",
    "print(hash_map.get_bucket_index('abcd'))\n",
    "print(hash_map.get_bucket_index('bcda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compression function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "class HashMap:\n",
    "    \n",
    "    def __init__(self, initial_size=10):\n",
    "        self.bucket_array = [None for _ in range(initial_size)]\n",
    "        self.p = 37\n",
    "        self.num_entries = 0\n",
    "        \n",
    "    def put(self, key, value):\n",
    "        pass\n",
    "    \n",
    "    def get(self, key):\n",
    "        pass\n",
    "    \n",
    "    def get_bucket_index(self, key):\n",
    "        return self.get_hash_code(key)\n",
    "    \n",
    "    def get_hash_code(self, key):\n",
    "        key = str(key)\n",
    "        num_buckets = len(self.bucket_array)\n",
    "        current_coefficient = 1\n",
    "        hash_code = 0\n",
    "        for character in key:\n",
    "            hash_code += ord(character) * current_coefficient\n",
    "            hash_code = hash_code % num_buckets\n",
    "            current_coefficient *= self.p\n",
    "            current_coefficient = current_coefficient % num_buckets\n",
    "            \n",
    "\n",
    "        return hash_code % num_buckets\n",
    "\n",
    "hash_map = HashMap()\n",
    "print(hash_map.get_bucket_index('abcd'))\n",
    "print(hash_map.get_bucket_index('bcda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collision Handling\n",
    "\n",
    "As discussed earlier, when two different inputs produce the same output, then we have a collision. Our implementation of `get_hash_code()` function is satisfactory. However, because we are using compression function, we are prone to collisions. \n",
    "\n",
    "Consider the following scenario. \n",
    "\n",
    "We have a bucket array of length 10 and we get two different hash codes for two different inputs, say 355, and 1095. Even though the hash codes are different in this case, the bucket index will be same because of the way we have implemented our compression function. Such scenarios where multiple entries want to go to the same bucket are very common. So, we introduce some logic to handle collisions.\n",
    "\n",
    "There are two popular ways in which we handle collisions.\n",
    "\n",
    "1. Closed Addressing or Separate chaining\n",
    "2. Open Addressing\n",
    "\n",
    "1. Closed addressing is a clever technique where we use the same bucket to store multiple objects. The bucket in this case will store a linked list of key-value pairs. Every bucket has it's own separate chain of linked list nodes.\n",
    "\n",
    "2. In open addressing, we do the following:\n",
    "    * If, after getting the bucket index,  the bucket is empty, we store the object in that particular bucket\n",
    "    \n",
    "    * If the bucket is not empty, we find an alternate bucket index by using another function which modifies the current hash code to give a new code\n",
    "    \n",
    "\n",
    "Separate chaining is a simple and effective technique to handle collisions and that is what we discuss here. \n",
    "\n",
    "Implement the `put` and `get` function using the idea of separate chaining. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 4\n",
      "one: 1\n",
      "neo: 11\n",
      "three: 3\n",
      "neo: 11\n",
      "neo: 10\n",
      "size: 4\n"
     ]
    }
   ],
   "source": [
    "class LinkedListNode:\n",
    "    def __init__(self, key, value):\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        self.next = None\n",
    "\n",
    "\n",
    "class HashMap:\n",
    "\n",
    "    def __init__(self, initial_size=10):\n",
    "        self.bucket_array = [None for _ in range(initial_size)]\n",
    "        self.p = 37\n",
    "        self.num_entries = 0\n",
    "\n",
    "    def put(self, key, value):\n",
    "        bucket_index = self.get_bucket_index(key)\n",
    "        new_node = LinkedListNode(key, value)\n",
    "        head = self.bucket_array[bucket_index]\n",
    "\n",
    "        while head is not None:\n",
    "            if head.key == key:\n",
    "                head.value = value\n",
    "                return\n",
    "            head = head.next\n",
    "\n",
    "        head = self.bucket_array[bucket_index]\n",
    "        new_node.nex = head\n",
    "        self.bucket_array[bucket_index] = new_node\n",
    "        self.num_entries += 1\n",
    "\n",
    "    def get(self, key):\n",
    "        bucket_index = self.get_bucket_index(key)\n",
    "        head = self.bucket_array[bucket_index]\n",
    "        while head is not None:\n",
    "            if head.key == key:\n",
    "                return head.value\n",
    "            head = head.next\n",
    "\n",
    "        return None\n",
    "\n",
    "    def get_bucket_index(self, key):\n",
    "        return self.get_hash_code(key)\n",
    "\n",
    "    def size(self):\n",
    "        return self.num_entries\n",
    "\n",
    "    def get_hash_code(self, key):\n",
    "        key = str(key)\n",
    "        num_buckets = len(self.bucket_array)\n",
    "        current_coefficient = 1\n",
    "        hash_code = 0\n",
    "        for character in key:\n",
    "            hash_code += ord(character) * current_coefficient\n",
    "            hash_code = hash_code % num_buckets\n",
    "            current_coefficient *= self.p\n",
    "            current_coefficient = current_coefficient % num_buckets\n",
    "\n",
    "        return hash_code % num_buckets\n",
    "\n",
    "hash_map = HashMap()\n",
    "\n",
    "hash_map.put(\"one\", 1)\n",
    "hash_map.put(\"two\", 2)\n",
    "hash_map.put(\"three\", 3)\n",
    "hash_map.put(\"neo\", 11)\n",
    "\n",
    "print(\"size: {}\".format(hash_map.size()))\n",
    "\n",
    "\n",
    "print(\"one: {}\".format(hash_map.get(\"one\")))\n",
    "print(\"neo: {}\".format(hash_map.get(\"neo\")))\n",
    "print(\"three: {}\".format(hash_map.get(\"three\")))\n",
    "print(\"neo: {}\".format(hash_map.get(\"neo\")))\n",
    "hash_map.put(\"neo\",10)\n",
    "print(\"neo: {}\".format(hash_map.get(\"neo\")))\n",
    "print(\"size: {}\".format(hash_map.size()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Get and Delete operation\n",
    "\n",
    "Can you figure out the time complexity for get and delete operation?\n",
    "\n",
    "*Answer: the solution follows the same logic and the time complexity is O(1). Note that we do not reduce the size of bucket array in delete operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rehashing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkedListNode:\n",
    "    \n",
    "    def __init__(self, key, value):\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        self.next = None\n",
    "\n",
    "class HashMap:\n",
    "    \n",
    "    def __init__(self, initial_size = 15):\n",
    "        self.bucket_array = [None for _ in range(initial_size)]\n",
    "        self.p = 31\n",
    "        self.num_entries = 0\n",
    "        self.load_factor = 0.7\n",
    "        \n",
    "    def put(self, key, value):\n",
    "        bucket_index = self.get_bucket_index(key)\n",
    "\n",
    "        new_node = LinkedListNode(key, value)\n",
    "        head = self.bucket_array[bucket_index]\n",
    "\n",
    "        # check if key is already present in the map, and update it's value\n",
    "        while head is not None:\n",
    "            if head.key == key:\n",
    "                head.value = value\n",
    "                return\n",
    "            head = head.next\n",
    "\n",
    "        # key not found in the chain --> create a new entry and place it at the head of the chain\n",
    "        head = self.bucket_array[bucket_index]\n",
    "        new_node.next = head\n",
    "        self.bucket_array[bucket_index] = new_node\n",
    "        self.num_entries += 1\n",
    "        \n",
    "        # check for load factor\n",
    "        current_load_factor = self.num_entries / len(self.bucket_array)\n",
    "        if current_load_factor > self.load_factor:\n",
    "            self.num_entries = 0\n",
    "            self._rehash()\n",
    "        \n",
    "    def get(self, key):\n",
    "        bucket_index = self.get_hash_code(key)\n",
    "        head = self.bucket_array[bucket_index]\n",
    "        while head is not None:\n",
    "            if head.key == key:\n",
    "                return head.value\n",
    "            head = head.next\n",
    "        return None\n",
    "        \n",
    "    def get_bucket_index(self, key):\n",
    "        bucket_index = self.get_hash_code(key)\n",
    "        return bucket_index\n",
    "    \n",
    "    def get_hash_code(self, key):\n",
    "        key = str(key)\n",
    "        num_buckets = len(self.bucket_array)\n",
    "        current_coefficient = 1\n",
    "        hash_code = 0\n",
    "        for character in key:\n",
    "            hash_code += ord(character) * current_coefficient\n",
    "            hash_code = hash_code % num_buckets                       # compress hash_code\n",
    "            current_coefficient *= self.p\n",
    "            current_coefficient = current_coefficient % num_buckets   # compress coefficient\n",
    "        return hash_code % num_buckets                                # one last compression before returning\n",
    "    \n",
    "    def size(self):\n",
    "        return self.num_entries\n",
    "\n",
    "    def _rehash(self):\n",
    "        old_num_buckets = len(self.bucket_array)\n",
    "        old_bucket_array = self.bucket_array\n",
    "        num_buckets = 2 * old_num_buckets\n",
    "        self.bucket_array = [None for _ in range(num_buckets)]\n",
    "\n",
    "        for head in old_bucket_array:\n",
    "            while head is not None:\n",
    "                key = head.key\n",
    "                value = head.value\n",
    "                self.put(key, value)         # we can use our put() method to rehash\n",
    "                head = head.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete Operation\n",
    "\n",
    "Can you implement delete operation using all we have learnt so far?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkedListNode:\n",
    "    \n",
    "    def __init__(self, key, value):\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        self.next = None\n",
    "\n",
    "class HashMap:\n",
    "    \n",
    "    def __init__(self, initial_size = 15):\n",
    "        self.bucket_array = [None for _ in range(initial_size)]\n",
    "        self.p = 31\n",
    "        self.num_entries = 0\n",
    "        self.load_factor = 0.7\n",
    "        \n",
    "    def put(self, key, value):\n",
    "        bucket_index = self.get_bucket_index(key)\n",
    "\n",
    "        new_node = LinkedListNode(key, value)\n",
    "        head = self.bucket_array[bucket_index]\n",
    "\n",
    "        # check if key is already present in the map, and update it's value\n",
    "        while head is not None:\n",
    "            if head.key == key:\n",
    "                head.value = value\n",
    "                return\n",
    "            head = head.next\n",
    "\n",
    "        # key not found in the chain --> create a new entry and place it at the head of the chain\n",
    "        head = self.bucket_array[bucket_index]\n",
    "        new_node.next = head\n",
    "        self.bucket_array[bucket_index] = new_node\n",
    "        self.num_entries += 1\n",
    "        \n",
    "        # check for load factor\n",
    "        current_load_factor = self.num_entries / len(self.bucket_array)\n",
    "        if current_load_factor > self.load_factor:\n",
    "            self.num_entries = 0\n",
    "            self._rehash()\n",
    "        \n",
    "    def get(self, key):\n",
    "        bucket_index = self.get_hash_code(key)\n",
    "        head = self.bucket_array[bucket_index]\n",
    "        while head is not None:\n",
    "            if head.key == key:\n",
    "                return head.value\n",
    "            head = head.next\n",
    "        return None\n",
    "        \n",
    "    def get_bucket_index(self, key):\n",
    "        bucket_index = self.get_hash_code(key)\n",
    "        return bucket_index\n",
    "    \n",
    "    def get_hash_code(self, key):\n",
    "        key = str(key)\n",
    "        num_buckets = len(self.bucket_array)\n",
    "        current_coefficient = 1\n",
    "        hash_code = 0\n",
    "        for character in key:\n",
    "            hash_code += ord(character) * current_coefficient\n",
    "            hash_code = hash_code % num_buckets                       # compress hash_code\n",
    "            current_coefficient *= self.p\n",
    "            current_coefficient = current_coefficient % num_buckets   # compress coefficient\n",
    "        return hash_code % num_buckets                                # one last compression before returning\n",
    "    \n",
    "    def size(self):\n",
    "        return self.num_entries\n",
    "\n",
    "    def _rehash(self):\n",
    "        old_num_buckets = len(self.bucket_array)\n",
    "        old_bucket_array = self.bucket_array\n",
    "        num_buckets = 2 * old_num_buckets\n",
    "        self.bucket_array = [None for _ in range(num_buckets)]\n",
    "\n",
    "        for head in old_bucket_array:\n",
    "            while head is not None:\n",
    "                key = head.key\n",
    "                value = head.value\n",
    "                self.put(key, value)         # we can use our put() method to rehash\n",
    "                head = head.next\n",
    "                \n",
    "    def delete(self, key):\n",
    "        bucket_index = self.get_bucket_index(key)\n",
    "        head = self.bucket_array[bucket_index]\n",
    "\n",
    "        previous = None\n",
    "        while head is not None:\n",
    "            # traverse the chain to find the key value\n",
    "            if head.key == key:\n",
    "                # if it is the first element in the chain\n",
    "                if previous is None:\n",
    "                    self.bucket_array[bucket_index] = head.next\n",
    "                else:\n",
    "                    previous.next = head.next\n",
    "                self.num_entries -= 1\n",
    "                return\n",
    "            else:\n",
    "                previous = head\n",
    "                head = head.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6c8cccf23fc189a51b8b2ae4ca3b98de763e12cce4f9033fe8d82721c91cecc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
